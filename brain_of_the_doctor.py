from dotenv import load_dotenv
load_dotenv()

import os
import sys
import base64
import time
import hashlib
import shutil
import tempfile
from functools import lru_cache
from groq import Groq, GroqError

# Try to get API key from environment variables first
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

def get_api_key():
    """Get API key from Streamlit secrets or environment variables"""
    try:
        import streamlit as st
        return st.secrets["GROQ_API_KEY"]
    except (ImportError, KeyError, AttributeError):
        return os.environ.get("GROQ_API_KEY")

def test_api_key(api_key):
    """Test if the provided API key is valid by making a minimal request"""
    try:
        client = Groq(api_key=api_key)
        # Make a minimal request to list available models or similar
        models = client.models.list()
        if models:
            return True
        return False
    except Exception as e:
        print(f"API key test failed: {str(e)}")
        return False

def handle_long_path(file_path):
    """Handle long file paths by creating a shorter temporary path"""
    try:
        # Create a temporary directory
        temp_dir = tempfile.mkdtemp()
        # Get the file extension
        _, ext = os.path.splitext(file_path)
        # Create a new shorter path
        new_path = os.path.join(temp_dir, f"temp{ext}")
        # Copy the file to the new location
        shutil.copy2(file_path, new_path)
        return new_path
    except Exception as e:
        print(f"Error handling long path: {str(e)}")
        return file_path

def encode_image(image_path, max_size=256):
    """Convert image to base64 string with optional resizing"""
    try:
        # Handle long paths
        image_path = handle_long_path(image_path)
        
        import cv2
        # Read and optionally resize image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Could not read image file")
            
        height, width = img.shape[:2]
        if max(height, width) > max_size:
            scale = max_size / max(height, width)
            img = cv2.resize(img, (0,0), fx=scale, fy=scale)
            
        # Encode with lower quality
        _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 60])
        encoded = base64.b64encode(buffer).decode('utf-8')
        return encoded
        
    except Exception:
        # Fallback to original method if OpenCV fails
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

PRESCRIPTION_TEMPLATE = """
PRESCRIPTION
Date: {date}
Patient: {patient_name}
Diagnosis: {diagnosis}

Medications:
{medications}

Instructions:
{instructions}

Doctor: AI Doctor
"""

import random

def generate_prescription(diagnosis, language="English"):
    """Generate a prescription based on diagnosis using AI to suggest medications."""
    from datetime import datetime

    if not diagnosis or not isinstance(diagnosis, str):
        raise ValueError("Diagnosis must be a non-empty string")

    date = datetime.now().strftime("%d/%m/%Y")
    
    # Use AI to generate appropriate medications based on the diagnosis
    client = Groq(api_key=get_api_key())
    
    # Language-specific prompts for medication generation with detailed instructions
    medication_prompts = {
        "English": """Based on the following medical diagnosis, provide 2-3 appropriate medications or treatments with specific instructions for each.
        For each medication, include: medication name, dosage, frequency, duration, and any special instructions.
        Return in this format:
        - Medication Name: Dosage instructions (e.g., 500mg tablet), Frequency (e.g., twice daily), Duration (e.g., for 7 days), Special instructions
        
        Diagnosis: {diagnosis}
        
        Medications with Instructions:""",
        
        "Hindi": """рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рджрд╛рди рдХреЗ рдЖрдзрд╛рд░ рдкрд░, рдкреНрд░рддреНрдпреЗрдХ рдХреЗ рд▓рд┐рдП рд╡рд┐рд╢рд┐рд╖реНрдЯ рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рд╕рд╛рде 2-3 рдЙрдкрдпреБрдХреНрдд рджрд╡рд╛рдПрдВ рдпрд╛ рдЙрдкрдЪрд╛рд░ рдкреНрд░рджрд╛рди рдХрд░реЗрдВред
        рдкреНрд░рддреНрдпреЗрдХ рджрд╡рд╛ рдХреЗ рд▓рд┐рдП рд╢рд╛рдорд┐рд▓ рдХрд░реЗрдВ: рджрд╡рд╛ рдХрд╛ рдирд╛рдо, рдЦреБрд░рд╛рдХ, рдЖрд╡реГрддреНрддрд┐, рдЕрд╡рдзрд┐ рдФрд░ рдХреЛрдИ рд╡рд┐рд╢реЗрд╖ рдирд┐рд░реНрджреЗрд╢ред
        рдЗрд╕ рдкреНрд░рд╛рд░реВрдк рдореЗрдВ рд▓реМрдЯрд╛рдПрдВ:
        - рджрд╡рд╛ рдХрд╛ рдирд╛рдо: рдЦреБрд░рд╛рдХ рдирд┐рд░реНрджреЗрд╢ (рдЙрджрд╛., 500mg рдЧреЛрд▓реА), рдЖрд╡реГрддреНрддрд┐ (рдЙрджрд╛., рджрд┐рди рдореЗрдВ рджреЛ рдмрд╛рд░), рдЕрд╡рдзрд┐ (рдЙрджрд╛., 7 рджрд┐рдиреЛрдВ рдХреЗ рд▓рд┐рдП), рд╡рд┐рд╢реЗрд╖ рдирд┐рд░реНрджреЗрд╢
        
        рдирд┐рджрд╛рди: {diagnosis}
        
        рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рд╕рд╛рде рджрд╡рд╛рдПрдВ:""",
        
        "Marathi": """рдЦрд╛рд▓реАрд▓ рд╡реИрджреНрдпрдХреАрдп рдирд┐рджрд╛рдирд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд, рдкреНрд░рддреНрдпреЗрдХрд╛рд╕рд╛рдареА рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╕реВрдЪрдирд╛рдВрд╕рд╣ реи-рей рдпреЛрдЧреНрдп рдФрд╖рдзреЗ рдХрд┐рдВрд╡рд╛ рдЙрдкрдЪрд╛рд░ рджреНрдпрд╛.
        рдкреНрд░рддреНрдпреЗрдХ рдФрд╖рдзрд╛рд╕рд╛рдареА рд╕рдорд╛рд╡рд┐рд╖реНрдЯ рдХрд░рд╛: рдФрд╖рдзрд╛рдЪреЗ рдирд╛рд╡, рдЦреБрд░рд╛рдХ, рд╡рд╛рд░рдВрд╡рд╛рд░рддрд╛, рдХрд╛рд▓рд╛рд╡рдзреА рдЖрдгрд┐ рдХреЛрдгрддреАрд╣реА рд╡рд┐рд╢реЗрд╖ рд╕реВрдЪрдирд╛.
        рдпрд╛ рд╕реНрд╡рд░реВрдкрд╛рдд рдкрд░рдд рдХрд░рд╛:
        - рдФрд╖рдзрд╛рдЪреЗ рдирд╛рд╡: рдЦреБрд░рд╛рдХ рд╕реВрдЪрдирд╛ (рдЙрджрд╛., 500mg рдЧреЛрд│реА), рд╡рд╛рд░рдВрд╡рд╛рд░рддрд╛ (рдЙрджрд╛., рджрд┐рд╡рд╕рд╛рддреВрди рджреЛрди рд╡реЗрд│рд╛), рдХрд╛рд▓рд╛рд╡рдзреА (рдЙрджрд╛., рен рджрд┐рд╡рд╕рд╛рдВрд╕рд╛рдареА), рд╡рд┐рд╢реЗрд╖ рд╕реВрдЪрдирд╛
        
        рдирд┐рджрд╛рди: {diagnosis}
        
        рд╕реВрдЪрдирд╛рдВрд╕рд╣ рдФрд╖рдзреЗ:"""
    }
    
    prompt_template = medication_prompts.get(language, medication_prompts["English"])
    prompt = prompt_template.format(diagnosis=diagnosis[:500])  # Limit diagnosis length
    
    try:
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "You are a medical professional providing medication recommendations."},
                {"role": "user", "content": prompt}
            ],
            model="llama3-8b-8192",
            max_tokens=150,
            temperature=0.3
        )
        
        medications_text = response.choices[0].message.content.strip()
        
        # Parse the medications from the response
        medications = []
        lines = medications_text.split('\n')
        
        for line in lines:
            line = line.strip()
            # Skip empty lines and lines that are just headers
            if not line or any(phrase in line.lower() for phrase in ["here is", "medications:", "list of", "following"]):
                continue
            
            # Handle different list formats
            if line.startswith(('-', 'тАв', '*', '1.', '2.', '3.')):
                # Clean up list items
                clean_med = line.replace('-', '').replace('тАв', '').replace('*', '').strip()
                # Remove numbering
                if clean_med and clean_med[0].isdigit() and '.' in clean_med:
                    clean_med = clean_med.split('.', 1)[1].strip()
                if clean_med and len(clean_med) > 3:
                    medications.append(clean_med)
            else:
                # Handle plain text medication names
                if len(line) > 3 and not any(word in line.lower() for word in ["medication", "treatment", "prescription"]):
                    medications.append(line)
        
        # If parsing failed, use fallback medications
        if not medications:
            fallback_meds = {
                "English": ["Consult healthcare professional for specific medication"],
                "Hindi": ["рд╡рд┐рд╢рд┐рд╖реНрдЯ рджрд╡рд╛ рдХреЗ рд▓рд┐рдП рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВ"],
                "Marathi": ["рд╡рд┐рд╢рд┐рд╖реНрдЯ рдФрд╖рдзрд╛рд╕рд╛рдареА рдЖрд░реЛрдЧреНрдпрд╕реЗрд╡рд╛ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрдЪрд╛ рд╕рд▓реНрд▓рд╛ рдШреНрдпрд╛"]
            }
            medications = fallback_meds.get(language, fallback_meds["English"])
            
    except Exception as e:
        print(f"Medication generation failed: {str(e)}")
        fallback_meds = {
            "English": ["Consult healthcare professional for medication"],
            "Hindi": ["рджрд╡рд╛ рдХреЗ рд▓рд┐рдП рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВ"],
            "Marathi": ["рдФрд╖рдзрд╛рд╕рд╛рдареА рдЖрд░реЛрдЧреНрдпрд╕реЗрд╡рд╛ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрдЪрд╛ рд╕рд▓реНрд▓рд╛ рдШреНрдпрд╛"]
        }
        medications = fallback_meds.get(language, fallback_meds["English"])

    templates = {
        "English": """
PRESCRIPTION
Date: {date}
Patient: [Patient Name]
Diagnosis: {diagnosis}

Medications:
{medications}

Doctor: AI Doctor
""",
        "Hindi": """
рдиреБрд╕реНрдЦрд╛
рджрд┐рдирд╛рдВрдХ: {date}
рд░реЛрдЧреА: [рд░реЛрдЧреА рдХрд╛ рдирд╛рдо]
рдирд┐рджрд╛рди: {diagnosis}

рджрд╡рд╛рдЗрдпрд╛рдВ:
{medications}

рдбреЙрдХреНрдЯрд░: AI Doctor
""",
        "Marathi": """
рдФрд╖рдзреЛрдкрдЪрд╛рд░
рджрд┐рдирд╛рдВрдХ: {date}
рд░реБрдЧреНрдг: [рд░реБрдЧреНрдгрд╛рдЪреЗ рдирд╛рд╡]
рдирд┐рджрд╛рди: {diagnosis}

рдФрд╖рдзреЗ:
{medications}

рдбреЙрдХреНрдЯрд░: AI Doctor
"""
    }

    template = templates.get(language, templates["English"])

    return template.format(
        date=date,
        diagnosis=diagnosis[:80] + "..." if len(diagnosis) > 80 else diagnosis,  # Show first 80 chars of diagnosis
        medications="\n".join(f"- {med}" for med in medications),
    )

@lru_cache(maxsize=100)
def analyze_image_with_query(query, encoded_image, language="English", model="llama3-8b-8192"):
    """Analyze image with text query using GROQ's vision model with caching"""
    import logging
    if not query or not encoded_image:
        logging.error("Missing required parameters for analyze_image_with_query")
        return "Error: Missing required parameters for image analysis."
        
    client = Groq(api_key=get_api_key())
    
    # Since llama3-8b-8192 doesn't support vision, we'll analyze the text query
    # and provide guidance based on the image context
    logging.info("Vision model not available, falling back to text analysis with image context")
    
    # Language-specific prompts for image-based analysis
    language_prompts = {
        "English": """You are a dermatology specialist AI assistant. A patient has uploaded an image of their skin condition and provided the following description. 
        Please analyze their symptoms and provide a comprehensive diagnosis.
        
        For skin conditions like dandruff, look for these symptoms in their description:
        1. White or yellowish flakes on the scalp
        2. Itchy scalp
        3. Dry or oily scalp
        4. Redness or inflammation
        5. Any visible skin changes or rashes
        
        Provide your analysis in this format:
        
        DIAGNOSIS:
        - Condition identified (based on described symptoms)
        - Severity level (Mild/Moderate/Severe)
        - Key symptoms mentioned
        
        RECOMMENDATIONS:
        - Immediate care steps
        - Lifestyle changes
        - Products to use/avoid
        
        PRESCRIPTION:
        - Specific medications or treatments
        - Application instructions
        - Follow-up timeline
        
        Note: This analysis is based on the patient's description. For more accurate diagnosis, please consult a healthcare professional.""",
        
        "Hindi": """рдЖрдк рдПрдХ рддреНрд╡рдЪрд╛ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ AI рд╕рд╣рд╛рдпрдХ рд╣реИрдВред рдПрдХ рд░реЛрдЧреА рдиреЗ рдЕрдкрдиреА рддреНрд╡рдЪрд╛ рдХреА рд╕реНрдерд┐рддрд┐ рдХреА рддрд╕реНрд╡реАрд░ рдЕрдкрд▓реЛрдб рдХреА рд╣реИ рдФрд░ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд╡рд┐рд╡рд░рдг рдкреНрд░рджрд╛рди рдХрд┐рдпрд╛ рд╣реИред
        рдХреГрдкрдпрд╛ рдЙрдирдХреЗ рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ рдФрд░ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдирд┐рджрд╛рди рдкреНрд░рджрд╛рди рдХрд░реЗрдВред
        
        рд░реВрд╕реА рдЬреИрд╕реА рддреНрд╡рдЪрд╛ рдХреА рд╕реНрдерд┐рддрд┐рдпреЛрдВ рдХреЗ рд▓рд┐рдП, рдЙрдирдХреЗ рд╡рд┐рд╡рд░рдг рдореЗрдВ рдЗрди рд▓рдХреНрд╖рдгреЛрдВ рдХреЛ рджреЗрдЦреЗрдВ:
        1. рд╕реНрдХреИрд▓реНрдк рдкрд░ рд╕рдлреЗрдж рдпрд╛ рдкреАрд▓реЗ рд░рдВрдЧ рдХреЗ рдлреНрд▓реЗрдХреНрд╕
        2. рдЦреБрдЬрд▓реА рд╡рд╛рд▓рд╛ рд╕реНрдХреИрд▓реНрдк
        3. рд╕реВрдЦрд╛ рдпрд╛ рддреИрд▓реАрдп рд╕реНрдХреИрд▓реНрдк
        4. рд▓рд╛рд▓рд┐рдорд╛ рдпрд╛ рд╕реВрдЬрди
        5. рдХреЛрдИ рджреГрд╢реНрдп рддреНрд╡рдЪрд╛ рдкрд░рд┐рд╡рд░реНрддрди рдпрд╛ рдЪрдХрддреНрддреЗ
        
        рдЕрдкрдирд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЗрд╕ рдкреНрд░рд╛рд░реВрдк рдореЗрдВ рдкреНрд░рджрд╛рди рдХрд░реЗрдВ:
        
        рдирд┐рджрд╛рди:
        - рдкрд╣рдЪрд╛рдиреА рдЧрдИ рд╕реНрдерд┐рддрд┐ (рд╡рд░реНрдгрд┐рдд рд▓рдХреНрд╖рдгреЛрдВ рдХреЗ рдЖрдзрд╛рд░ рдкрд░)
        - рдЧрдВрднреАрд░рддрд╛ рд╕реНрддрд░ (рд╣рд▓реНрдХрд╛/рдордзреНрдпрдо/рдЧрдВрднреАрд░)
        - рдореБрдЦреНрдп рд▓рдХреНрд╖рдг
        
        рд╕рд┐рдлрд╛рд░рд┐рд╢реЗрдВ:
        - рддрддреНрдХрд╛рд▓ рджреЗрдЦрднрд╛рд▓ рдХреЗ рдХрджрдо
        - рдЬреАрд╡рдирд╢реИрд▓реА рдореЗрдВ рдкрд░рд┐рд╡рд░реНрддрди
        - рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ/рдмрдЪрдиреЗ рдХреЗ рдЙрддреНрдкрд╛рдж
        
        рдиреБрд╕реНрдЦрд╛:
        - рд╡рд┐рд╢рд┐рд╖реНрдЯ рджрд╡рд╛рдПрдВ рдпрд╛ рдЙрдкрдЪрд╛рд░
        - рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдирд┐рд░реНрджреЗрд╢
        - рдлреЙрд▓реЛ-рдЕрдк рд╕рдордп
        
        рдиреЛрдЯ: рдпрд╣ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд░реЛрдЧреА рдХреЗ рд╡рд┐рд╡рд░рдг рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рд╣реИред рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдПрдХ рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВред""",
        
        "Marathi": """рддреБрдореНрд╣реА рдПрдХ рддреНрд╡рдЪрд╛рд░реЛрдЧ рддрдЬреНрдЬреНрдЮ AI рд╕рд╣рд╛рдпреНрдпрдХ рдЖрд╣рд╛рдд. рдПрдХ рд░реБрдЧреНрдгрд╛рдиреЗ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рддреНрд╡рдЪреЗрдЪреНрдпрд╛ рд╕реНрдерд┐рддреАрдЪреЗ рдЪрд┐рддреНрд░ рдЕрдкрд▓реЛрдб рдХреЗрд▓реЗ рдЖрд╣реЗ рдЖрдгрд┐ рдЦрд╛рд▓реАрд▓ рд╡рд░реНрдгрди рдкреНрд░рджрд╛рди рдХреЗрд▓реЗ рдЖрд╣реЗ.
        рдХреГрдкрдпрд╛ рддреНрдпрд╛рдВрдЪреНрдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рд╛ рдЖрдгрд┐ рдПрдХ рд╡реНрдпрд╛рдкрдХ рдирд┐рджрд╛рди рджреНрдпрд╛.
        
        рдХреЛрдВрдбреНрдпрд╛рд╕рд╛рд░рдЦреНрдпрд╛ рддреНрд╡рдЪреЗрдЪреНрдпрд╛ рд╕реНрдерд┐рддреАрдВрд╕рд╛рдареА, рддреНрдпрд╛рдВрдЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рдд рдпрд╛ рд▓рдХреНрд╖рдгреЗ рд╢реЛрдзрд╛:
        1. рдбреЛрдХреНрдпрд╛рд╡рд░ рдкрд╛рдВрдврд░реЗ рдХрд┐рдВрд╡рд╛ рдкрд┐рд╡рд│реЗ рдлреНрд▓реЗрдХреНрд╕
        2. рдЦрд╛рдЬ рд╕реБрдЯрдгрд╛рд░реЗ рдбреЛрдХреЗ
        3. рдХреЛрд░рдбреЗ рдХрд┐рдВрд╡рд╛ рддреИрд▓рдпреБрдХреНрдд рдбреЛрдХреЗ
        4. рд▓рд╛рд▓рд╕рд░рдкрдгрд╛ рдХрд┐рдВрд╡рд╛ рд╕реВрдЬ
        5. рдХреЛрдгрддреЗрд╣реА рджреГрд╢реНрдп рддреНрд╡рдЪрд╛ рдмрджрд▓ рдХрд┐рдВрд╡рд╛ рдкреБрд░рд│
        
        рддреБрдордЪреЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдпрд╛ рд╕реНрд╡рд░реВрдкрд╛рдд рджреНрдпрд╛:
        
        рдирд┐рджрд╛рди:
        - рдУрд│рдЦрд▓реЗрд▓реА рд╕реНрдерд┐рддреА (рд╡рд░реНрдгрди рдХреЗрд▓реЗрд▓реНрдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреНрдпрд╛ рдЖрдзрд╛рд░реЗ)
        - рдЧрдВрднреАрд░рддрд╛ рдкрд╛рддрд│реА (рд╣рд▓рдХреА/рдордзреНрдпрдо/рдЧрдВрднреАрд░)
        - рдореБрдЦреНрдп рд▓рдХреНрд╖рдгреЗ
        
        рд╢рд┐рдлрд╛рд░рд╕реА:
        - рддреНрд╡рд░рд┐рдд рдХрд╛рд│рдЬреАрдЪреЗ рдкрд╛рд╡рд▓реЗ
        - рдЬреАрд╡рдирд╢реИрд▓реА рдмрджрд▓
        - рд╡рд╛рдкрд░рдгреНрдпрд╛рд╕рд╛рдареА/рдЯрд╛рд│рдгреНрдпрд╛рд╕рд╛рдареА рдЙрддреНрдкрд╛рджрдиреЗ
        
        рдФрд╖рдзреЛрдкрдЪрд╛рд░:
        - рд╡рд┐рд╢рд┐рд╖реНрдЯ рдФрд╖рдзреЗ рдХрд┐рдВрд╡рд╛ рдЙрдкрдЪрд╛рд░
        - рд╡рд╛рдкрд░рдгреНрдпрд╛рдЪреНрдпрд╛ рд╕реВрдЪрдирд╛
        - рдкреБрдиреНрд╣рд╛ рддрдкрд╛рд╕рдгреА рд╡реЗрд│
        
        рдЯреАрдк: рд╣реЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд░реБрдЧреНрдгрд╛рдЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдЖрд╣реЗ. рдЕрдзрд┐рдХ рдЕрдЪреВрдХ рдирд┐рджрд╛рдирд╛рд╕рд╛рдареА, рдХреГрдкрдпрд╛ рд╡реИрджреНрдпрдХреАрдп рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрд╢реА рд╕рд▓реНрд▓рд╛рдорд╕рд▓рдд рдХрд░рд╛."""
    }
    
    # Get the appropriate prompt for the selected language
    system_prompt = language_prompts.get(language, language_prompts["English"])
    
    # Create a comprehensive query that includes image context
    enhanced_query = f"""Patient has uploaded an image of their skin condition and reports: {query}
    
    Please provide a detailed medical analysis based on their description. Consider common skin conditions that match their symptoms.
    
    Focus on providing helpful medical guidance while noting that this is based on their description and not a direct visual analysis."""
    
    messages = [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": enhanced_query
        }
    ]
    
    try:
        response = client.chat.completions.create(
            messages=messages,
            model=model,
            max_tokens=800
        )
        content = response.choices[0].message.content
        if not isinstance(content, str):
            content = str(content)
        if not content.strip():
            logging.error("Empty response content from analyze_image_with_query")
            return "Error: Empty response from image analysis."
        
        # Add a note about the analysis method
        note = {
            "English": "\n\nNote: This analysis is based on your description. For more accurate diagnosis, please consult a healthcare professional.",
            "Hindi": "\n\nрдиреЛрдЯ: рдпрд╣ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдЖрдкрдХреЗ рд╡рд┐рд╡рд░рдг рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рд╣реИред рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рдирд┐рджрд╛рди рдХреЗ рд▓рд┐рдП, рдХреГрдкрдпрд╛ рдПрдХ рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рд╕реЗ рдкрд░рд╛рдорд░реНрд╢ рдХрд░реЗрдВред",
            "Marathi": "\n\nрдЯреАрдк: рд╣реЗ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рддреБрдордЪреНрдпрд╛ рд╡рд░реНрдгрдирд╛рд╡рд░ рдЖрдзрд╛рд░рд┐рдд рдЖрд╣реЗ. рдЕрдзрд┐рдХ рдЕрдЪреВрдХ рдирд┐рджрд╛рдирд╛рд╕рд╛рдареА, рдХреГрдкрдпрд╛ рд╡реИрджреНрдпрдХреАрдп рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХрд╛рдВрд╢реА рд╕рд▓реНрд▓рд╛рдорд╕рд▓рдд рдХрд░рд╛."
        }
        
        return content + note.get(language, note["English"])
        
    except Exception as e:
        logging.error(f"Vision analysis failed: {str(e)}")
        if "model_not_found" in str(e):
            return analyze_text_query(query, language)
        return f"Vision analysis failed: {str(e)}"

# Validate GROQ API key
if not GROQ_API_KEY:
    error_msg = """
    ERROR: GROQ_API_KEY not found. Please make sure it's set in:
    1. Streamlit secrets (for deployment) - st.secrets["GROQ_API_KEY"]
    2. Environment variables (for local development) - GROQ_API_KEY
    3. .env file (for local development) - GROQ_API_KEY=your_key_here
    
    You can get an API key from: https://console.groq.com/
    """
    print(error_msg)
    # Don't exit in Streamlit environment, just show error
    if 'streamlit' not in sys.modules:
        sys.exit(1)
else:
    print(f"ЁЯФС API Key Status: Found (Length: {len(GROQ_API_KEY)} characters)")
    if GROQ_API_KEY.startswith("gsk_"):
        print("тЬЕ API Key format looks correct (starts with 'gsk_')")
        # Test the API key
        if test_api_key(GROQ_API_KEY):
            print("тЬЕ API Key is valid and working!")
        else:
            print("тЭМ API Key test failed - key may be invalid or expired")
    else:
        print("тЪая╕П API Key format may be incorrect (should start with 'gsk_')")

def analyze_image(image_path):
    """Analyze image using computer vision"""
    try:
        from image_analysis import analyze_image_colors
        analysis = analyze_image_colors(image_path)
        return f"Image analysis results: Dominant colors are {', '.join(analysis['dominant_colors'])}"
    except Exception as e:
        raise ValueError(f"Image analysis failed: {str(e)}")

@lru_cache(maxsize=100)
def analyze_text_query(query, language="English", model="llama3-8b-8192", max_retries=3):
    """Process text queries with GROQ API with caching and focused diagnosis"""
    import logging
    if not query or not isinstance(query, str):
        logging.error("Invalid query parameter for analyze_text_query")
        return "Error: Invalid query parameter."
        
    client = Groq(api_key=get_api_key())
    
    # Language-specific prompts with varied response patterns - focused on concise diagnosis only
    language_prompts = {
        "English": [
            "You are a medical specialist. Provide a concise diagnosis for these symptoms. Focus on the most likely condition and key symptoms. Keep it brief:",
            "As a healthcare professional, give a quick medical assessment of these symptoms. Be concise and focus on the primary diagnosis:",
            "Provide a brief medical diagnosis of these symptoms. Keep it short and focused on the main condition:"
        ],
        "Hindi": [
            "рдЖрдк рдПрдХ рдЪрд┐рдХрд┐рддреНрд╕рд╛ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╣реИрдВред рдЗрди рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рдирд┐рджрд╛рди рдкреНрд░рджрд╛рди рдХрд░реЗрдВред рдореБрдЦреНрдп рд╕реНрдерд┐рддрд┐ рдФрд░ рдкреНрд░рдореБрдЦ рд▓рдХреНрд╖рдгреЛрдВ рдкрд░ рдзреНрдпрд╛рди рджреЗрдВред рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣реЗрдВ:",
            "рдПрдХ рд╕реНрд╡рд╛рд╕реНрдереНрдп рджреЗрдЦрднрд╛рд▓ рдкреЗрд╢реЗрд╡рд░ рдХреЗ рд░реВрдк рдореЗрдВ, рдЗрди рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдЖрдХрд▓рди рджреЗрдВред рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣реЗрдВ рдФрд░ рдкреНрд░рд╛рдердорд┐рдХ рдирд┐рджрд╛рди рдкрд░ рдзреНрдпрд╛рди рджреЗрдВ:",
            "рдЗрди рд▓рдХреНрд╖рдгреЛрдВ рдХрд╛ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рдЪрд┐рдХрд┐рддреНрд╕рд╛ рдирд┐рджрд╛рди рдкреНрд░рджрд╛рди рдХрд░реЗрдВред рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣реЗрдВ рдФрд░ рдореБрдЦреНрдп рд╕реНрдерд┐рддрд┐ рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░реЗрдВ:"
        ],
        "Marathi": [
            "рддреБрдореНрд╣реА рдПрдХ рд╡реИрджреНрдпрдХреАрдп рддрдЬреНрдЬреНрдЮ рдЖрд╣рд╛рдд. рдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рдирд┐рджрд╛рди рджреНрдпрд╛. рдореБрдЦреНрдп рд╕реНрдерд┐рддреА рдЖрдгрд┐ рдкреНрд░рдореБрдЦ рд▓рдХреНрд╖рдгрд╛рдВрд╡рд░ рд▓рдХреНрд╖ рдХреЗрдВрджреНрд░рд┐рдд рдХрд░рд╛. рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣рд╛:",
            "рдЖрд░реЛрдЧреНрдпрд╕реЗрд╡рд╛ рд╡реНрдпрд╛рд╡рд╕рд╛рдпрд┐рдХ рдореНрд╣рдгреВрди, рдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╡реИрджреНрдпрдХреАрдп рдореВрд▓реНрдпрд╛рдВрдХрди рджреНрдпрд╛. рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣рд╛ рдЖрдгрд┐ рдкреНрд░рд╛рдердорд┐рдХ рдирд┐рджрд╛рдирд╛рд╡рд░ рд▓рдХреНрд╖ рдХреЗрдВрджреНрд░рд┐рдд рдХрд░рд╛:",
            "рдпрд╛ рд▓рдХреНрд╖рдгрд╛рдВрдЪреЗ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╡реИрджреНрдпрдХреАрдп рдирд┐рджрд╛рди рджреНрдпрд╛. рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд░рд╣рд╛ рдЖрдгрд┐ рдореБрдЦреНрдп рд╕реНрдерд┐рддреАрд╡рд░ рд▓рдХреНрд╖ рдХреЗрдВрджреНрд░рд┐рдд рдХрд░рд╛:"
        ]
    }
    
    # Get random prompt for the selected language to add variability
    prompts = language_prompts.get(language, language_prompts["English"])
    system_prompt = random.choice(prompts) if isinstance(prompts, list) else prompts
    
    # Add some variability to the query to get different responses
    query_variations = [
        query,
        f"Patient reports: {query}. Please provide medical analysis.",
        f"Symptoms described: {query}. Need professional diagnosis.",
        f"Medical consultation request: {query}"
    ]
    
    user_query = random.choice(query_variations)
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_query}
    ]

    last_error = None
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                messages=messages,
                model=model,
                max_tokens=800,
                temperature=0.7  # Add some randomness to responses
            )
            
            if not response.choices:
                logging.error("Empty response from API in analyze_text_query")
                return "Error: Empty response from text analysis."
                
            content = response.choices[0].message.content
            print("MODEL RAW OUTPUT:", repr(content))
            if not isinstance(content, str):
                content = str(content)
            if not content.strip():
                logging.error("Empty content string from analyze_text_query")
                return "Error: Empty content from text analysis."
            
            # Add some post-processing to ensure varied responses
            diagnosis_variations = [
                content,
                f"MEDICAL ANALYSIS:\n{content}",
                f"DIAGNOSTIC ASSESSMENT:\n{content}",
                f"CLINICAL EVALUATION:\n{content}"
            ]
            
            return random.choice(diagnosis_variations)
            
        except GroqError as e:
            last_error = e
            if attempt < max_retries - 1:
                time.sleep(1 * (attempt + 1))  # Exponential backoff
                continue
            logging.error(f"API request failed after {max_retries} attempts: {str(e)}")
            return f"Text analysis failed: {str(e)}"
            
        except Exception as e:
            logging.error(f"Analysis failed: {str(e)}")
            return f"Text analysis failed: {str(e)}"

if __name__ == "__main__":
    os.system("python D:\\EDIT KAREGE\\ai-doctor-2.0-voice-and-vision\\ai-doctor-2.0-voice-and-vision\\ai_doctor_fully_fixed.py")
