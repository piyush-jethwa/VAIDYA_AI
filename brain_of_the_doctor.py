from dotenv import load_dotenv
load_dotenv()

import os
import sys
import base64
import time
import hashlib
import shutil
import tempfile
from functools import lru_cache
from groq import Groq, GroqError

# Try to get API key from environment variables first
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

def get_api_key():
    """Get API key from Streamlit secrets or environment variables"""
    try:
        import streamlit as st
        return st.secrets["GROQ_API_KEY"]
    except (ImportError, KeyError, AttributeError):
        return os.environ.get("GROQ_API_KEY")

def test_api_key(api_key):
    """Test if the provided API key is valid by making a minimal request"""
    try:
        client = Groq(api_key=api_key)
        # Make a minimal request to list available models or similar
        models = client.models.list()
        if models:
            return True
        return False
    except Exception as e:
        print(f"API key test failed: {str(e)}")
        return False

def handle_long_path(file_path):
    """Handle long file paths by creating a shorter temporary path"""
    try:
        # Create a temporary directory
        temp_dir = tempfile.mkdtemp()
        # Get the file extension
        _, ext = os.path.splitext(file_path)
        # Create a new shorter path
        new_path = os.path.join(temp_dir, f"temp{ext}")
        # Copy the file to the new location
        shutil.copy2(file_path, new_path)
        return new_path
    except Exception as e:
        print(f"Error handling long path: {str(e)}")
        return file_path

def encode_image(image_path, max_size=256):
    """Convert image to base64 string with optional resizing"""
    try:
        # Handle long paths
        image_path = handle_long_path(image_path)
        
        import cv2
        # Read and optionally resize image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Could not read image file")
            
        height, width = img.shape[:2]
        if max(height, width) > max_size:
            scale = max_size / max(height, width)
            img = cv2.resize(img, (0,0), fx=scale, fy=scale)
            
        # Encode with lower quality
        _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 60])
        encoded = base64.b64encode(buffer).decode('utf-8')
        return encoded
        
    except Exception:
        # Fallback to original method if OpenCV fails
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

PRESCRIPTION_TEMPLATE = """
PRESCRIPTION
Date: {date}
Patient: {patient_name}
Diagnosis: {diagnosis}

Medications:
{medications}

Instructions:
{instructions}

Doctor: AI Doctor
"""

import random

def generate_prescription(diagnosis, language="English"):
    """Generate a prescription based on diagnosis using AI to suggest medications."""
    from datetime import datetime

    if not diagnosis or not isinstance(diagnosis, str):
        raise ValueError("Diagnosis must be a non-empty string")

    date = datetime.now().strftime("%d/%m/%Y")
    
    # Use AI to generate appropriate medications based on the diagnosis
    client = Groq(api_key=get_api_key())
    
    # Language-specific prompts for medication generation with detailed instructions
    medication_prompts = {
        "English": """Based on the following medical diagnosis, provide 2-3 appropriate medications or treatments with specific instructions for each.
        For each medication, include: medication name, dosage, frequency, duration, and any special instructions.
        Return in this format:
        - Medication Name: Dosage instructions (e.g., 500mg tablet), Frequency (e.g., twice daily), Duration (e.g., for 7 days), Special instructions
        
        Diagnosis: {diagnosis}
        
        Medications with Instructions:""",
        
        "Hindi": """‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§®‡§ø‡§¶‡§æ‡§® ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞, ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• 2-3 ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§¶‡§µ‡§æ‡§è‡§Ç ‡§Ø‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§
        ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§¶‡§µ‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•á‡§Ç: ‡§¶‡§µ‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ, ‡§ñ‡•Å‡§∞‡§æ‡§ï, ‡§Ü‡§µ‡•É‡§§‡•ç‡§§‡§ø, ‡§Ö‡§µ‡§ß‡§ø ‡§î‡§∞ ‡§ï‡•ã‡§à ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•§
        ‡§á‡§∏ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§≤‡•å‡§ü‡§æ‡§è‡§Ç:
        - ‡§¶‡§µ‡§æ ‡§ï‡§æ ‡§®‡§æ‡§Æ: ‡§ñ‡•Å‡§∞‡§æ‡§ï ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ (‡§â‡§¶‡§æ., 500mg ‡§ó‡•ã‡§≤‡•Ä), ‡§Ü‡§µ‡•É‡§§‡•ç‡§§‡§ø (‡§â‡§¶‡§æ., ‡§¶‡§ø‡§® ‡§Æ‡•á‡§Ç ‡§¶‡•ã ‡§¨‡§æ‡§∞), ‡§Ö‡§µ‡§ß‡§ø (‡§â‡§¶‡§æ., 7 ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è), ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂
        
        ‡§®‡§ø‡§¶‡§æ‡§®: {diagnosis}
        
        ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§¶‡§µ‡§æ‡§è‡§Ç:""",
        
        "Marathi": """‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§®‡§ø‡§¶‡§æ‡§®‡§æ‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§, ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï‡§æ‡§∏‡§æ‡§†‡•Ä ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∏‡•Ç‡§ö‡§®‡§æ‡§Ç‡§∏‡§π ‡•®-‡•© ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§î‡§∑‡§ß‡•á ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§¶‡•ç‡§Ø‡§æ.
        ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡•á‡§ï ‡§î‡§∑‡§ß‡§æ‡§∏‡§æ‡§†‡•Ä ‡§∏‡§Æ‡§æ‡§µ‡§ø‡§∑‡•ç‡§ü ‡§ï‡§∞‡§æ: ‡§î‡§∑‡§ß‡§æ‡§ö‡•á ‡§®‡§æ‡§µ, ‡§ñ‡•Å‡§∞‡§æ‡§ï, ‡§µ‡§æ‡§∞‡§Ç‡§µ‡§æ‡§∞‡§§‡§æ, ‡§ï‡§æ‡§≤‡§æ‡§µ‡§ß‡•Ä ‡§Ü‡§£‡§ø ‡§ï‡•ã‡§£‡§§‡•Ä‡§π‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∏‡•Ç‡§ö‡§®‡§æ.
        ‡§Ø‡§æ ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™‡§æ‡§§ ‡§™‡§∞‡§§ ‡§ï‡§∞‡§æ:
        - ‡§î‡§∑‡§ß‡§æ‡§ö‡•á ‡§®‡§æ‡§µ: ‡§ñ‡•Å‡§∞‡§æ‡§ï ‡§∏‡•Ç‡§ö‡§®‡§æ (‡§â‡§¶‡§æ., 500mg ‡§ó‡•ã‡§≥‡•Ä), ‡§µ‡§æ‡§∞‡§Ç‡§µ‡§æ‡§∞‡§§‡§æ (‡§â‡§¶‡§æ., ‡§¶‡§ø‡§µ‡§∏‡§æ‡§§‡•Ç‡§® ‡§¶‡•ã‡§® ‡§µ‡•á‡§≥‡§æ), ‡§ï‡§æ‡§≤‡§æ‡§µ‡§ß‡•Ä (‡§â‡§¶‡§æ., ‡•≠ ‡§¶‡§ø‡§µ‡§∏‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä), ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§∏‡•Ç‡§ö‡§®‡§æ
        
        ‡§®‡§ø‡§¶‡§æ‡§®: {diagnosis}
        
        ‡§∏‡•Ç‡§ö‡§®‡§æ‡§Ç‡§∏‡§π ‡§î‡§∑‡§ß‡•á:"""
    }
    
    prompt_template = medication_prompts.get(language, medication_prompts["English"])
    prompt = prompt_template.format(diagnosis=diagnosis[:500])  # Limit diagnosis length
    
    try:
        response = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "You are a medical professional providing medication recommendations."},
                {"role": "user", "content": prompt}
            ],
            model="llama3-8b-8192",
            max_tokens=150,
            temperature=0.3
        )
        
        medications_text = response.choices[0].message.content.strip()
        
        # Parse the medications from the response
        medications = []
        lines = medications_text.split('\n')
        
        for line in lines:
            line = line.strip()
            # Skip empty lines and lines that are just headers
            if not line or any(phrase in line.lower() for phrase in ["here is", "medications:", "list of", "following"]):
                continue
            
            # Handle different list formats
            if line.startswith(('-', '‚Ä¢', '*', '1.', '2.', '3.')):
                # Clean up list items
                clean_med = line.replace('-', '').replace('‚Ä¢', '').replace('*', '').strip()
                # Remove numbering
                if clean_med and clean_med[0].isdigit() and '.' in clean_med:
                    clean_med = clean_med.split('.', 1)[1].strip()
                if clean_med and len(clean_med) > 3:
                    medications.append(clean_med)
            else:
                # Handle plain text medication names
                if len(line) > 3 and not any(word in line.lower() for word in ["medication", "treatment", "prescription"]):
                    medications.append(line)
        
        # If parsing failed, use fallback medications
        if not medications:
            fallback_meds = {
                "English": ["Consult healthcare professional for specific medication"],
                "Hindi": ["‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§¶‡§µ‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç"],
                "Marathi": ["‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§î‡§∑‡§ß‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø‡§∏‡•á‡§µ‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§ò‡•ç‡§Ø‡§æ"]
            }
            medications = fallback_meds.get(language, fallback_meds["English"])
            
    except Exception as e:
        print(f"Medication generation failed: {str(e)}")
        fallback_meds = {
            "English": ["Consult healthcare professional for medication"],
            "Hindi": ["‡§¶‡§µ‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç"],
            "Marathi": ["‡§î‡§∑‡§ß‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø‡§∏‡•á‡§µ‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§ò‡•ç‡§Ø‡§æ"]
        }
        medications = fallback_meds.get(language, fallback_meds["English"])

    templates = {
        "English": """
PRESCRIPTION
Date: {date}
Patient: [Patient Name]
Diagnosis: {diagnosis}

Medications:
{medications}

Doctor: AI Doctor
""",
        "Hindi": """
‡§®‡•Å‡§∏‡•ç‡§ñ‡§æ
‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï: {date}
‡§∞‡•ã‡§ó‡•Ä: [‡§∞‡•ã‡§ó‡•Ä ‡§ï‡§æ ‡§®‡§æ‡§Æ]
‡§®‡§ø‡§¶‡§æ‡§®: {diagnosis}

‡§¶‡§µ‡§æ‡§á‡§Ø‡§æ‡§Ç:
{medications}

‡§°‡•â‡§ï‡•ç‡§ü‡§∞: AI Doctor
""",
        "Marathi": """
‡§î‡§∑‡§ß‡•ã‡§™‡§ö‡§æ‡§∞
‡§¶‡§ø‡§®‡§æ‡§Ç‡§ï: {date}
‡§∞‡•Å‡§ó‡•ç‡§£: [‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§ö‡•á ‡§®‡§æ‡§µ]
‡§®‡§ø‡§¶‡§æ‡§®: {diagnosis}

‡§î‡§∑‡§ß‡•á:
{medications}

‡§°‡•â‡§ï‡•ç‡§ü‡§∞: AI Doctor
"""
    }

    template = templates.get(language, templates["English"])

    return template.format(
        date=date,
        diagnosis=diagnosis[:80] + "..." if len(diagnosis) > 80 else diagnosis,  # Show first 80 chars of diagnosis
        medications="\n".join(f"- {med}" for med in medications),
    )

@lru_cache(maxsize=100)
def analyze_image_with_query(query, encoded_image, language="English", model="llama3-8b-8192"):
    """Analyze image with text query using GROQ's vision model with caching"""
    import logging
    if not query or not encoded_image:
        logging.error("Missing required parameters for analyze_image_with_query")
        return "Error: Missing required parameters for image analysis."
        
    client = Groq(api_key=get_api_key())
    
    # Since llama3-8b-8192 doesn't support vision, we'll analyze the text query
    # and provide guidance based on the image context
    logging.info("Vision model not available, falling back to text analysis with image context")
    
    # Language-specific prompts for image-based analysis
    language_prompts = {
        "English": """You are a dermatology specialist AI assistant. A patient has uploaded an image of their skin condition and provided the following description. 
        Please analyze their symptoms and provide a comprehensive diagnosis.
        
        For skin conditions like dandruff, look for these symptoms in their description:
        1. White or yellowish flakes on the scalp
        2. Itchy scalp
        3. Dry or oily scalp
        4. Redness or inflammation
        5. Any visible skin changes or rashes
        
        Provide your analysis in this format:
        
        DIAGNOSIS:
        - Condition identified (based on described symptoms)
        - Severity level (Mild/Moderate/Severe)
        - Key symptoms mentioned
        
        RECOMMENDATIONS:
        - Immediate care steps
        - Lifestyle changes
        - Products to use/avoid
        
        PRESCRIPTION:
        - Specific medications or treatments
        - Application instructions
        - Follow-up timeline
        
        Note: This analysis is based on the patient's description. For more accurate diagnosis, please consult a healthcare professional.""",
        
        "Hindi": """‡§Ü‡§™ ‡§è‡§ï ‡§§‡•ç‡§µ‡§ö‡§æ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§ ‡§è‡§ï ‡§∞‡•ã‡§ó‡•Ä ‡§®‡•á ‡§Ö‡§™‡§®‡•Ä ‡§§‡•ç‡§µ‡§ö‡§æ ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡•Ä ‡§§‡§∏‡•ç‡§µ‡•Ä‡§∞ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§
        ‡§ï‡•É‡§™‡§Ø‡§æ ‡§â‡§®‡§ï‡•á ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§®‡§ø‡§¶‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§
        
        ‡§∞‡•Ç‡§∏‡•Ä ‡§ú‡•à‡§∏‡•Ä ‡§§‡•ç‡§µ‡§ö‡§æ ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§â‡§®‡§ï‡•á ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§á‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§¶‡•á‡§ñ‡•á‡§Ç:
        1. ‡§∏‡•ç‡§ï‡•à‡§≤‡•ç‡§™ ‡§™‡§∞ ‡§∏‡§´‡•á‡§¶ ‡§Ø‡§æ ‡§™‡•Ä‡§≤‡•á ‡§∞‡§Ç‡§ó ‡§ï‡•á ‡§´‡•ç‡§≤‡•á‡§ï‡•ç‡§∏
        2. ‡§ñ‡•Å‡§ú‡§≤‡•Ä ‡§µ‡§æ‡§≤‡§æ ‡§∏‡•ç‡§ï‡•à‡§≤‡•ç‡§™
        3. ‡§∏‡•Ç‡§ñ‡§æ ‡§Ø‡§æ ‡§§‡•à‡§≤‡•Ä‡§Ø ‡§∏‡•ç‡§ï‡•à‡§≤‡•ç‡§™
        4. ‡§≤‡§æ‡§≤‡§ø‡§Æ‡§æ ‡§Ø‡§æ ‡§∏‡•Ç‡§ú‡§®
        5. ‡§ï‡•ã‡§à ‡§¶‡•É‡§∂‡•ç‡§Ø ‡§§‡•ç‡§µ‡§ö‡§æ ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§Ø‡§æ ‡§ö‡§ï‡§§‡•ç‡§§‡•á
        
        ‡§Ö‡§™‡§®‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§á‡§∏ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç:
        
        ‡§®‡§ø‡§¶‡§æ‡§®:
        - ‡§™‡§π‡§ö‡§æ‡§®‡•Ä ‡§ó‡§à ‡§∏‡•ç‡§•‡§ø‡§§‡§ø (‡§µ‡§∞‡•ç‡§£‡§ø‡§§ ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞)
        - ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ ‡§∏‡•ç‡§§‡§∞ (‡§π‡§≤‡•ç‡§ï‡§æ/‡§Æ‡§ß‡•ç‡§Ø‡§Æ/‡§ó‡§Ç‡§≠‡•Ä‡§∞)
        - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§≤‡§ï‡•ç‡§∑‡§£
        
        ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂‡•á‡§Ç:
        - ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ï‡•á ‡§ï‡§¶‡§Æ
        - ‡§ú‡•Ä‡§µ‡§®‡§∂‡•à‡§≤‡•Ä ‡§Æ‡•á‡§Ç ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§®
        - ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á/‡§¨‡§ö‡§®‡•á ‡§ï‡•á ‡§â‡§§‡•ç‡§™‡§æ‡§¶
        
        ‡§®‡•Å‡§∏‡•ç‡§ñ‡§æ:
        - ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§¶‡§µ‡§æ‡§è‡§Ç ‡§Ø‡§æ ‡§â‡§™‡§ö‡§æ‡§∞
        - ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂
        - ‡§´‡•â‡§≤‡•ã-‡§Ö‡§™ ‡§∏‡§Æ‡§Ø
        
        ‡§®‡•ã‡§ü: ‡§Ø‡§π ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§∞‡•ã‡§ó‡•Ä ‡§ï‡•á ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§π‡•à‡•§ ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§ü‡•Ä‡§ï ‡§®‡§ø‡§¶‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§""",
        
        "Marathi": """‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§ï ‡§§‡•ç‡§µ‡§ö‡§æ‡§∞‡•ã‡§ó ‡§§‡§ú‡•ç‡§ú‡•ç‡§û AI ‡§∏‡§π‡§æ‡§Ø‡•ç‡§Ø‡§ï ‡§Ü‡§π‡§æ‡§§. ‡§è‡§ï ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§®‡•á ‡§§‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§§‡•ç‡§µ‡§ö‡•á‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä‡§ö‡•á ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡•á‡§≤‡•á ‡§Ü‡§π‡•á ‡§Ü‡§£‡§ø ‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§µ‡§∞‡•ç‡§£‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡•á‡§≤‡•á ‡§Ü‡§π‡•á.
        ‡§ï‡•É‡§™‡§Ø‡§æ ‡§§‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§ö‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡§æ ‡§Ü‡§£‡§ø ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§®‡§ø‡§¶‡§æ‡§® ‡§¶‡•ç‡§Ø‡§æ.
        
        ‡§ï‡•ã‡§Ç‡§°‡•ç‡§Ø‡§æ‡§∏‡§æ‡§∞‡§ñ‡•ç‡§Ø‡§æ ‡§§‡•ç‡§µ‡§ö‡•á‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä‡§Ç‡§∏‡§æ‡§†‡•Ä, ‡§§‡•ç‡§Ø‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§£‡§®‡§æ‡§§ ‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡•á ‡§∂‡•ã‡§ß‡§æ:
        1. ‡§°‡•ã‡§ï‡•ç‡§Ø‡§æ‡§µ‡§∞ ‡§™‡§æ‡§Ç‡§¢‡§∞‡•á ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§™‡§ø‡§µ‡§≥‡•á ‡§´‡•ç‡§≤‡•á‡§ï‡•ç‡§∏
        2. ‡§ñ‡§æ‡§ú ‡§∏‡•Å‡§ü‡§£‡§æ‡§∞‡•á ‡§°‡•ã‡§ï‡•á
        3. ‡§ï‡•ã‡§∞‡§°‡•á ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§§‡•à‡§≤‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§°‡•ã‡§ï‡•á
        4. ‡§≤‡§æ‡§≤‡§∏‡§∞‡§™‡§£‡§æ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§∏‡•Ç‡§ú
        5. ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä ‡§¶‡•É‡§∂‡•ç‡§Ø ‡§§‡•ç‡§µ‡§ö‡§æ ‡§¨‡§¶‡§≤ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§™‡•Å‡§∞‡§≥
        
        ‡§§‡•Å‡§Æ‡§ö‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§Ø‡§æ ‡§∏‡•ç‡§µ‡§∞‡•Ç‡§™‡§æ‡§§ ‡§¶‡•ç‡§Ø‡§æ:
        
        ‡§®‡§ø‡§¶‡§æ‡§®:
        - ‡§ì‡§≥‡§ñ‡§≤‡•á‡§≤‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä (‡§µ‡§∞‡•ç‡§£‡§® ‡§ï‡•á‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§Ü‡§ß‡§æ‡§∞‡•á)
        - ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ ‡§™‡§æ‡§§‡§≥‡•Ä (‡§π‡§≤‡§ï‡•Ä/‡§Æ‡§ß‡•ç‡§Ø‡§Æ/‡§ó‡§Ç‡§≠‡•Ä‡§∞)
        - ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§≤‡§ï‡•ç‡§∑‡§£‡•á
        
        ‡§∂‡§ø‡§´‡§æ‡§∞‡§∏‡•Ä:
        - ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§ï‡§æ‡§≥‡§ú‡•Ä‡§ö‡•á ‡§™‡§æ‡§µ‡§≤‡•á
        - ‡§ú‡•Ä‡§µ‡§®‡§∂‡•à‡§≤‡•Ä ‡§¨‡§¶‡§≤
        - ‡§µ‡§æ‡§™‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä/‡§ü‡§æ‡§≥‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§®‡•á
        
        ‡§î‡§∑‡§ß‡•ã‡§™‡§ö‡§æ‡§∞:
        - ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§î‡§∑‡§ß‡•á ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§â‡§™‡§ö‡§æ‡§∞
        - ‡§µ‡§æ‡§™‡§∞‡§£‡•ç‡§Ø‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∏‡•Ç‡§ö‡§®‡§æ
        - ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§§‡§™‡§æ‡§∏‡§£‡•Ä ‡§µ‡•á‡§≥
        
        ‡§ü‡•Ä‡§™: ‡§π‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§£‡§®‡§æ‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Ü‡§π‡•á. ‡§Ö‡§ß‡§ø‡§ï ‡§Ö‡§ö‡•Ç‡§ï ‡§®‡§ø‡§¶‡§æ‡§®‡§æ‡§∏‡§æ‡§†‡•Ä, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§æ‡§Ç‡§∂‡•Ä ‡§∏‡§≤‡•ç‡§≤‡§æ‡§Æ‡§∏‡§≤‡§§ ‡§ï‡§∞‡§æ."""
    }
    
    # Get the appropriate prompt for the selected language
    system_prompt = language_prompts.get(language, language_prompts["English"])
    
    # Add explicit language instruction to the system prompt
    language_instructions = {
        "English": "Respond in English only.",
        "Hindi": "‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç‡•§",
        "Marathi": "‡§ï‡•á‡§µ‡§≥ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ç‡§Ø‡§æ‡•§"
    }
    
    system_prompt = f"{system_prompt} {language_instructions.get(language, 'Respond in English only.')}"
    
    # Create a comprehensive query that includes image context
    enhanced_query = f"""Patient has uploaded an image of their skin condition and reports: {query}
    
    Please provide a detailed medical analysis based on their description. Consider common skin conditions that match their symptoms.
    
    Focus on providing helpful medical guidance while noting that this is based on their description and not a direct visual analysis."""
    
    messages = [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": enhanced_query
        }
    ]
    
    try:
        response = client.chat.completions.create(
            messages=messages,
            model=model,
            max_tokens=800
        )
        content = response.choices[0].message.content
        if not isinstance(content, str):
            content = str(content)
        if not content.strip():
            logging.error("Empty response content from analyze_image_with_query")
            return "Error: Empty response from image analysis."
        
        # Add a note about the analysis method
        note = {
            "English": "\n\nNote: This analysis is based on your description. For more accurate diagnosis, please consult a healthcare professional.",
            "Hindi": "\n\n‡§®‡•ã‡§ü: ‡§Ø‡§π ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§Ü‡§™‡§ï‡•á ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§π‡•à‡•§ ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§ü‡•Ä‡§ï ‡§®‡§ø‡§¶‡§æ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§",
            "Marathi": "\n\n‡§ü‡•Ä‡§™: ‡§π‡•á ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§£‡§®‡§æ‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Ü‡§π‡•á. ‡§Ö‡§ß‡§ø‡§ï ‡§Ö‡§ö‡•Ç‡§ï ‡§®‡§ø‡§¶‡§æ‡§®‡§æ‡§∏‡§æ‡§†‡•Ä, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§æ‡§Ç‡§∂‡•Ä ‡§∏‡§≤‡•ç‡§≤‡§æ‡§Æ‡§∏‡§≤‡§§ ‡§ï‡§∞‡§æ."
        }
        
        return content + note.get(language, note["English"])
        
    except Exception as e:
        logging.error(f"Vision analysis failed: {str(e)}")
        if "model_not_found" in str(e):
            return analyze_text_query(query, language)
        return f"Vision analysis failed: {str(e)}"

# Validate GROQ API key
if not GROQ_API_KEY:
    error_msg = """
    ERROR: GROQ_API_KEY not found. Please make sure it's set in:
    1. Streamlit secrets (for deployment) - st.secrets["GROQ_API_KEY"]
    2. Environment variables (for local development) - GROQ_API_KEY
    3. .env file (for local development) - GROQ_API_KEY=your_key_here
    
    You can get an API key from: https://console.groq.com/
    """
    print(error_msg)
    # Don't exit in Streamlit environment, just show error
    if 'streamlit' not in sys.modules:
        sys.exit(1)
else:
    print(f"üîë API Key Status: Found (Length: {len(GROQ_API_KEY)} characters)")
    if GROQ_API_KEY.startswith("gsk_"):
        print("‚úÖ API Key format looks correct (starts with 'gsk_')")
        # Test the API key
        if test_api_key(GROQ_API_KEY):
            print("‚úÖ API Key is valid and working!")
        else:
            print("‚ùå API Key test failed - key may be invalid or expired")
    else:
        print("‚ö†Ô∏è API Key format may be incorrect (should start with 'gsk_')")

def analyze_image(image_path):
    """Analyze image using computer vision"""
    try:
        from image_analysis import analyze_image_colors
        analysis = analyze_image_colors(image_path)
        return f"Image analysis results: Dominant colors are {', '.join(analysis['dominant_colors'])}"
    except Exception as e:
        raise ValueError(f"Image analysis failed: {str(e)}")

@lru_cache(maxsize=100)
def analyze_text_query(query, language="English", model="llama3-8b-8192", max_retries=3):
    """Process text queries with GROQ API with caching and focused diagnosis"""
    import logging
    if not query or not isinstance(query, str):
        logging.error("Invalid query parameter for analyze_text_query")
        return "Error: Invalid query parameter."
        
    client = Groq(api_key=get_api_key())
    
    # Language-specific prompts with varied response patterns - focused on concise diagnosis only
    language_prompts = {
        "English": [
            "You are a medical specialist. Provide a concise diagnosis for these symptoms. Focus on the most likely condition and key symptoms. Keep it brief:",
            "As a healthcare professional, give a quick medical assessment of these symptoms. Be concise and focus on the primary diagnosis:",
            "Provide a brief medical diagnosis of these symptoms. Keep it short and focused on the main condition:"
        ],
        "Hindi": [
            "‡§Ü‡§™ ‡§è‡§ï ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ ‡§á‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§®‡§ø‡§¶‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§î‡§∞ ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç‡•§ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡•á‡§Ç:",
            "‡§è‡§ï ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç, ‡§á‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§Ü‡§ï‡§≤‡§® ‡§¶‡•á‡§Ç‡•§ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡•á‡§Ç ‡§î‡§∞ ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§®‡§ø‡§¶‡§æ‡§® ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡•á‡§Ç:",
            "‡§á‡§® ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§®‡§ø‡§¶‡§æ‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡•á‡§Ç ‡§î‡§∞ ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç:"
        ],
        "Marathi": [
            "‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§è‡§ï ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§§‡§ú‡•ç‡§ú‡•ç‡§û ‡§Ü‡§π‡§æ‡§§. ‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§ö‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§®‡§ø‡§¶‡§æ‡§® ‡§¶‡•ç‡§Ø‡§æ. ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä ‡§Ü‡§£‡§ø ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§µ‡§∞ ‡§≤‡§ï‡•ç‡§∑ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§æ. ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡§æ:",
            "‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø‡§∏‡•á‡§µ‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï ‡§Æ‡•ç‡§π‡§£‡•Ç‡§®, ‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§ö‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§Æ‡•Ç‡§≤‡•ç‡§Ø‡§æ‡§Ç‡§ï‡§® ‡§¶‡•ç‡§Ø‡§æ. ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡§æ ‡§Ü‡§£‡§ø ‡§™‡•ç‡§∞‡§æ‡§•‡§Æ‡§ø‡§ï ‡§®‡§ø‡§¶‡§æ‡§®‡§æ‡§µ‡§∞ ‡§≤‡§ï‡•ç‡§∑ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§æ:",
            "‡§Ø‡§æ ‡§≤‡§ï‡•ç‡§∑‡§£‡§æ‡§Ç‡§ö‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§®‡§ø‡§¶‡§æ‡§® ‡§¶‡•ç‡§Ø‡§æ. ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∞‡§π‡§æ ‡§Ü‡§£‡§ø ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§∏‡•ç‡§•‡§ø‡§§‡•Ä‡§µ‡§∞ ‡§≤‡§ï‡•ç‡§∑ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§æ:"
        ]
    }
    
    # Get random prompt for the selected language to add variability
    prompts = language_prompts.get(language, language_prompts["English"])
    system_prompt = random.choice(prompts) if isinstance(prompts, list) else prompts
    
    # Add explicit language instruction to the system prompt
    language_instructions = {
        "English": "Respond in English only.",
        "Hindi": "‡§ï‡•á‡§µ‡§≤ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç‡•§",
        "Marathi": "‡§ï‡•á‡§µ‡§≥ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ç‡§Ø‡§æ‡•§"
    }
    
    system_prompt_with_language = f"{system_prompt} {language_instructions.get(language, 'Respond in English only.')}"
    
    # Add some variability to the query to get different responses
    query_variations = [
        query,
        f"Patient reports: {query}. Please provide medical analysis.",
        f"Symptoms described: {query}. Need professional diagnosis.",
        f"Medical consultation request: {query}"
    ]
    
    user_query = random.choice(query_variations)
    
    messages = [
        {"role": "system", "content": system_prompt_with_language},
        {"role": "user", "content": user_query}
    ]

    last_error = None
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                messages=messages,
                model=model,
                max_tokens=800,
                temperature=0.7  # Add some randomness to responses
            )
            
            if not response.choices:
                logging.error("Empty response from API in analyze_text_query")
                return "Error: Empty response from text analysis."
                
            content = response.choices[0].message.content
            print("MODEL RAW OUTPUT:", repr(content))
            if not isinstance(content, str):
                content = str(content)
            if not content.strip():
                logging.error("Empty content string from analyze_text_query")
                return "Error: Empty content from text analysis."
            
            # Add some post-processing to ensure varied responses
            diagnosis_variations = [
                content,
                f"MEDICAL ANALYSIS:\n{content}",
                f"DIAGNOSTIC ASSESSMENT:\n{content}",
                f"CLINICAL EVALUATION:\n{content}"
            ]
            
            return random.choice(diagnosis_variations)
            
        except GroqError as e:
            last_error = e
            if attempt < max_retries - 1:
                time.sleep(1 * (attempt + 1))  # Exponential backoff
                continue
            logging.error(f"API request failed after {max_retries} attempts: {str(e)}")
            return f"Text analysis failed: {str(e)}"
            
        except Exception as e:
            logging.error(f"Analysis failed: {str(e)}")
            return f"Text analysis failed: {str(e)}"

if __name__ == "__main__":
    os.system("python D:\\EDIT KAREGE\\ai-doctor-2.0-voice-and-vision\\ai-doctor-2.0-voice-and-vision\\ai_doctor_fully_fixed.py")
